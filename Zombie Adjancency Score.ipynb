{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zombie Adjanceny Score\n",
    "#### The new z-score for the zombie apocolypse\n",
    "\n",
    "The idea behind the Zombie Ajanceny Score (z-score) is to assume that actors in Zombie movies become infected as Zombies and see how how the virus would spread throughout Hollywood using the IMDB database and NetworkX.  The virus is assumed to spread to other actors who share a movie with an infected actor.  Those closest to the most original infected actors and hence most likely to be infected would have a high Zombie Adjency Score whereas those furthest away and least likely to be infected would have a lower score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import networkx as nx\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepping the data\n",
    "Here I import various tables from the IMDB database.  The tables can be found [here](https://datasets.imdbws.com/) and descriptions of the metadata can be found [here](https://www.imdb.com/interfaces/).  I then use the .head() command to take a look at all the tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>ordering</th>\n",
       "      <th>nconst</th>\n",
       "      <th>category</th>\n",
       "      <th>job</th>\n",
       "      <th>characters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0000001</td>\n",
       "      <td>1</td>\n",
       "      <td>nm1588970</td>\n",
       "      <td>self</td>\n",
       "      <td>\\N</td>\n",
       "      <td>[\"Herself\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0000001</td>\n",
       "      <td>2</td>\n",
       "      <td>nm0005690</td>\n",
       "      <td>director</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0000001</td>\n",
       "      <td>3</td>\n",
       "      <td>nm0374658</td>\n",
       "      <td>cinematographer</td>\n",
       "      <td>director of photography</td>\n",
       "      <td>\\N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0000002</td>\n",
       "      <td>1</td>\n",
       "      <td>nm0721526</td>\n",
       "      <td>director</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0000002</td>\n",
       "      <td>2</td>\n",
       "      <td>nm1335271</td>\n",
       "      <td>composer</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tconst  ordering     nconst         category                      job  \\\n",
       "0  tt0000001         1  nm1588970             self                       \\N   \n",
       "1  tt0000001         2  nm0005690         director                       \\N   \n",
       "2  tt0000001         3  nm0374658  cinematographer  director of photography   \n",
       "3  tt0000002         1  nm0721526         director                       \\N   \n",
       "4  tt0000002         2  nm1335271         composer                       \\N   \n",
       "\n",
       "    characters  \n",
       "0  [\"Herself\"]  \n",
       "1           \\N  \n",
       "2           \\N  \n",
       "3           \\N  \n",
       "4           \\N  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load Principals, Titles, Names, Attributes\n",
    "principals = pd.read_csv('principals.tsv' , sep='\\t')\n",
    "titles = pd.read_csv('title.basics.tsv' , sep='\\t', low_memory=False) \n",
    "names = pd.read_csv('name_basics.tsv' , sep='\\t') \n",
    "ratings = pd.read_csv('title.ratings.tsv' , sep='\\t')\n",
    "principals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>titleType</th>\n",
       "      <th>primaryTitle</th>\n",
       "      <th>originalTitle</th>\n",
       "      <th>isAdult</th>\n",
       "      <th>startYear</th>\n",
       "      <th>endYear</th>\n",
       "      <th>runtimeMinutes</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0000001</td>\n",
       "      <td>short</td>\n",
       "      <td>Carmencita</td>\n",
       "      <td>Carmencita</td>\n",
       "      <td>0</td>\n",
       "      <td>1894</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1</td>\n",
       "      <td>Documentary,Short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0000002</td>\n",
       "      <td>short</td>\n",
       "      <td>Le clown et ses chiens</td>\n",
       "      <td>Le clown et ses chiens</td>\n",
       "      <td>0</td>\n",
       "      <td>1892</td>\n",
       "      <td>\\N</td>\n",
       "      <td>5</td>\n",
       "      <td>Animation,Short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0000003</td>\n",
       "      <td>short</td>\n",
       "      <td>Pauvre Pierrot</td>\n",
       "      <td>Pauvre Pierrot</td>\n",
       "      <td>0</td>\n",
       "      <td>1892</td>\n",
       "      <td>\\N</td>\n",
       "      <td>4</td>\n",
       "      <td>Animation,Comedy,Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0000004</td>\n",
       "      <td>short</td>\n",
       "      <td>Un bon bock</td>\n",
       "      <td>Un bon bock</td>\n",
       "      <td>0</td>\n",
       "      <td>1892</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>Animation,Short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0000005</td>\n",
       "      <td>short</td>\n",
       "      <td>Blacksmith Scene</td>\n",
       "      <td>Blacksmith Scene</td>\n",
       "      <td>0</td>\n",
       "      <td>1893</td>\n",
       "      <td>\\N</td>\n",
       "      <td>1</td>\n",
       "      <td>Comedy,Short</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tconst titleType            primaryTitle           originalTitle  \\\n",
       "0  tt0000001     short              Carmencita              Carmencita   \n",
       "1  tt0000002     short  Le clown et ses chiens  Le clown et ses chiens   \n",
       "2  tt0000003     short          Pauvre Pierrot          Pauvre Pierrot   \n",
       "3  tt0000004     short             Un bon bock             Un bon bock   \n",
       "4  tt0000005     short        Blacksmith Scene        Blacksmith Scene   \n",
       "\n",
       "   isAdult startYear endYear runtimeMinutes                    genres  \n",
       "0        0      1894      \\N              1         Documentary,Short  \n",
       "1        0      1892      \\N              5           Animation,Short  \n",
       "2        0      1892      \\N              4  Animation,Comedy,Romance  \n",
       "3        0      1892      \\N             \\N           Animation,Short  \n",
       "4        0      1893      \\N              1              Comedy,Short  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nconst</th>\n",
       "      <th>primaryName</th>\n",
       "      <th>birthYear</th>\n",
       "      <th>deathYear</th>\n",
       "      <th>primaryProfession</th>\n",
       "      <th>knownForTitles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nm0000001</td>\n",
       "      <td>Fred Astaire</td>\n",
       "      <td>1899</td>\n",
       "      <td>1987</td>\n",
       "      <td>soundtrack,actor,miscellaneous</td>\n",
       "      <td>tt0053137,tt0043044,tt0072308,tt0050419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nm0000002</td>\n",
       "      <td>Lauren Bacall</td>\n",
       "      <td>1924</td>\n",
       "      <td>2014</td>\n",
       "      <td>actress,soundtrack</td>\n",
       "      <td>tt0037382,tt0038355,tt0117057,tt0071877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nm0000003</td>\n",
       "      <td>Brigitte Bardot</td>\n",
       "      <td>1934</td>\n",
       "      <td>\\N</td>\n",
       "      <td>actress,soundtrack,producer</td>\n",
       "      <td>tt0054452,tt0049189,tt0059956,tt0057345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nm0000004</td>\n",
       "      <td>John Belushi</td>\n",
       "      <td>1949</td>\n",
       "      <td>1982</td>\n",
       "      <td>actor,writer,soundtrack</td>\n",
       "      <td>tt0080455,tt0078723,tt0072562,tt0077975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nm0000005</td>\n",
       "      <td>Ingmar Bergman</td>\n",
       "      <td>1918</td>\n",
       "      <td>2007</td>\n",
       "      <td>writer,director,actor</td>\n",
       "      <td>tt0083922,tt0069467,tt0050976,tt0050986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      nconst      primaryName birthYear deathYear  \\\n",
       "0  nm0000001     Fred Astaire      1899      1987   \n",
       "1  nm0000002    Lauren Bacall      1924      2014   \n",
       "2  nm0000003  Brigitte Bardot      1934        \\N   \n",
       "3  nm0000004     John Belushi      1949      1982   \n",
       "4  nm0000005   Ingmar Bergman      1918      2007   \n",
       "\n",
       "                primaryProfession                           knownForTitles  \n",
       "0  soundtrack,actor,miscellaneous  tt0053137,tt0043044,tt0072308,tt0050419  \n",
       "1              actress,soundtrack  tt0037382,tt0038355,tt0117057,tt0071877  \n",
       "2     actress,soundtrack,producer  tt0054452,tt0049189,tt0059956,tt0057345  \n",
       "3         actor,writer,soundtrack  tt0080455,tt0078723,tt0072562,tt0077975  \n",
       "4           writer,director,actor  tt0083922,tt0069467,tt0050976,tt0050986  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>averageRating</th>\n",
       "      <th>numVotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0000001</td>\n",
       "      <td>5.7</td>\n",
       "      <td>1527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0000002</td>\n",
       "      <td>6.2</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0000003</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0000004</td>\n",
       "      <td>6.3</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0000005</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tconst  averageRating  numVotes\n",
       "0  tt0000001            5.7      1527\n",
       "1  tt0000002            6.2       185\n",
       "2  tt0000003            6.5      1174\n",
       "3  tt0000004            6.3       114\n",
       "4  tt0000005            6.1      1889"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I engage in some paring down of the dataset.  Principals has almost 35 million rows.  There are also some columns that are not needed for the analysis which can be dropped.  The following are the changes made to the dataset:\n",
    "    1. Narrow down the type of artwork to movies only\n",
    "    2. Removing adult movies\n",
    "    3. Removing all non-actors (eg. directors, writers, etc.)\n",
    "    4. Narrow down to only living actors.  It is assumed that the dead actors would already be zombies!\n",
    "    5. Removing films that have less than 1000 reviews on IMDB\n",
    "\n",
    "I use some print commands to show how many rows were eliminated.  The output is percentage of size the new dataframe is to the original, the number of rows in the new dataframe and the number of rows in the original data frame.  From the last line we can see that the new dataframe is a mere 91k rows and is .26% the size of the original.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1 10.69% 3737875 34961324\n",
      "#2 10.52% 3677477 34961324\n",
      "#3 4.65% 1625187 34961324\n",
      "#4 3.41% 1193244 34961324\n",
      "#5 0.26% 91023 34961324\n"
     ]
    }
   ],
   "source": [
    "#Clean Principals\n",
    "  #use Titles to get movies only\n",
    "movie_IDs = titles[titles['titleType'] == 'movie']['tconst'].unique()\n",
    "principals_final = principals[principals['tconst'].isin(movie_IDs)]\n",
    "print (\"#1\", \"{0:.2%}\".format(round(len(principals_final)) / len (principals),4), len(principals_final), len (principals))\n",
    "  #Use isAdult to remove porn\n",
    "non_adult_IDs = titles[titles['isAdult'] == 0]['tconst'].unique()\n",
    "principals_final = principals_final[principals_final['tconst'].isin(non_adult_IDs)]\n",
    "print (\"#2\", \"{0:.2%}\".format(round(len(principals_final)) / len (principals),4), len(principals_final), len (principals))\n",
    "  #Keep only Actor, Actresses\n",
    "principals_final = principals_final[principals_final['category'].isin(['actor', 'actress'])]\n",
    "print (\"#3\", \"{0:.2%}\".format(round(len(principals_final)) / len (principals),4), len(principals_final), len (principals))\n",
    "  #Use death date to get living only\n",
    "living = names[names['deathYear'].str.isnumeric() == False]['nconst'].unique().tolist()\n",
    "principals_final = principals_final[principals_final['nconst'].isin(living)]\n",
    "print (\"#4\", \"{0:.2%}\".format(round(len(principals_final)) / len (principals),4), len(principals_final), len (principals))\n",
    "  #Use ratings to get only those that are > than 1000 ratings\n",
    "ratings_1000 = ratings[ratings['numVotes']>=1000]['tconst'].tolist()\n",
    "principals_final = principals_final[principals_final['tconst'].isin(ratings_1000)]\n",
    "print (\"#5\", \"{0:.2%}\".format(round(len(principals_final)) / len (principals),4), len(principals_final), len (principals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I remove all columns except for nconst and tconst which are IMBDs unique keys for person names and title names.  I then further reduce the data by keeping the Top 100, 1,000 and 10,000 actors based on the number of films they are in.  This allows me to experiment with the size of the dataset that is a large as possible without taking too long to run.  I eventually settled on Top1000 actors as the best size for me.  In the Addendum there is a network_eval function that can be used to help select the best size for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create sorted groupby of actors for 3ish buckets of N size\n",
    "principals_final = principals_final[['tconst', 'nconst']]\n",
    "sorted_principals = principals_final.groupby(['nconst'])['tconst'].count().sort_values(ascending = False).index\n",
    "Top100_actors = principals_final[principals_final['nconst'].isin(sorted_principals[:99])]\n",
    "Top1000_actors = principals_final[principals_final['nconst'].isin(sorted_principals[:999])]\n",
    "Top10000_actors = principals_final[principals_final['nconst'].isin(sorted_principals[:9999])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4939, 24520, 62472, 91023)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###See the length of possible dataframes to use\n",
    "len (Top100_actors), len (Top1000_actors), len (Top10000_actors), len (principals_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up I load the lists of Zombie movies to determine the initially infected actors.  I then add the names to each of the four dataframes. \n",
    "\n",
    "The lists of Zombie movies comes from four user defined lists:\n",
    "[pete-john-mcgarvey,](https://www.imdb.com/list/ls059468572/)\n",
    "[bigfatbaloney,](https://www.imdb.com/list/ls055027705/)\n",
    "[aronharde,](https://www.imdb.com/list/ls062760555/)\n",
    "[smothlop](https://www.imdb.com/list/ls073818691/)\n",
    "\n",
    "Note: IMDB has its own Python library [IMDbY](https://imdbpy.github.io/).  This library does have a search by topic function which I tried, but the results I got were a little od.  I have an example in the addendum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the Zombie Lists\n",
    "bfb = pd.read_csv('Complete zombie movies list - bigfatbaloney.csv', encoding='latin1')\n",
    "ah = pd.read_csv('Zombie Movies - aronharde.csv', encoding='latin1')\n",
    "pjm = pd.read_csv('zombie movies - pete-john-mcgarvey.csv', encoding='latin1')\n",
    "sl = pd.read_csv('zombie movies - smothlop.csv', encoding='latin1')\n",
    "all_lists = pd.concat([ah,bfb,pjm,sl])\n",
    "all_lists = all_lists[all_lists['Num Votes'] > 1000]\n",
    "all_lists = all_lists[all_lists['Title Type'] == 'movie']\n",
    "all_zombie_movie_ids = all_lists['Const'].unique().tolist()\n",
    "\n",
    "title_merge = titles[['tconst', 'primaryTitle']]\n",
    "names_merge = names[['nconst', 'primaryName']]\n",
    "\n",
    "def add_names(df, ids):\n",
    "    df['isZombie'] = df['tconst'].isin(ids)\n",
    "    #Replace tconst and nconst with actual names for the target dfs\n",
    "    df = df.merge(title_merge, how = 'left', left_on = 'tconst', right_on = 'tconst')\n",
    "    df = df.merge(names_merge, how = 'left', left_on = 'nconst', right_on = 'nconst')\n",
    "    df.drop(['tconst', 'nconst'], axis = 1, inplace = True)\n",
    "    return df\n",
    "\n",
    "Top100_actors = add_names(Top100_actors,all_zombie_movie_ids )\n",
    "Top1000_actors = add_names(Top1000_actors,all_zombie_movie_ids )\n",
    "Top10000_actors = add_names(Top10000_actors,all_zombie_movie_ids )\n",
    "principals_final = add_names(principals_final,all_zombie_movie_ids )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the Zombie Adjancency Score \n",
    "The function below takes one of the dataframes (in this case Top1000_actors) and creates a graph using NetworkX.  I then use the shortest_path from NetworkX to get a path from each original;y infected actor to a possible infectee.  Because NetworkX includes movies as part of the path, I need remove them to get to my definition of an infection path.  I also mandate that the infection path can only be a length of 6 or less via the max_hops variable.  \n",
    "\n",
    "The function returns a dataframe of possible infectees with their z-score as well as a network graph to allows us some additional analysis.  As ususal, I output some stats about the network and how long it takes the function to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_infectees(df):\n",
    "    start = time.time()\n",
    "    graph = nx.from_pandas_dataframe(df, 'primaryTitle', 'primaryName')\n",
    "    print ('network created')\n",
    "    print ('network is connected: ',nx.is_connected(graph))\n",
    "    print ('edges: ', len(graph.edges()))\n",
    "    print ('nodes: ', len(graph.nodes()))\n",
    "    print (f'Time to create network: {(time.time() - start):.2f} seconds')  ##Change to start time\n",
    "    net_time = time.time()\n",
    "    z_dict = {}\n",
    "    zombies = df[df['isZombie'] == True]['primaryName'].unique().tolist()\n",
    "    actors = df['primaryName'].unique().tolist()\n",
    "    movie_names = df['primaryTitle'].unique().tolist()\n",
    "    max_hops = 6\n",
    "    for actor in actors:       \n",
    "        z_dict[actor] = 0\n",
    "        for zombie in zombies:\n",
    "            if nx.has_path(graph, zombie, actor):\n",
    "                path = nx.shortest_path(graph, source=zombie, target=actor)\n",
    "                value = max(max_hops - (len(path) - len ([i for i in path if i in movie_names])), 0)\n",
    "                z_dict[actor] = z_dict[actor]+value\n",
    "    df['z_score'] = df['primaryName'].map(z_dict)\n",
    "    df.sort_values(by='z_score', ascending = False, inplace = True)\n",
    "    print (f'Total time: {(time.time() - net_time)/60:.2f} minutes')\n",
    "    return df[df['isZombie'] == False].drop(columns = ['primaryTitle']).drop_duplicates(), graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "network created\n",
      "network is connected:  False\n",
      "edges:  24513\n",
      "nodes:  13713\n",
      "Time to create network: 0.27 seconds\n",
      "Total time: 1.49 minutes\n"
     ]
    }
   ],
   "source": [
    "infected, contagion_graph = get_infectees(Top1000_actors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can now see who is most and least likely to be infected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 most likely to be infected:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>primaryName</th>\n",
       "      <th>z_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4947</th>\n",
       "      <td>Nicolas Cage</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3620</th>\n",
       "      <td>Ray Liotta</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21009</th>\n",
       "      <td>Samuel L. Jackson</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21231</th>\n",
       "      <td>Robert De Niro</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7648</th>\n",
       "      <td>Bruce Willis</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8329</th>\n",
       "      <td>Ving Rhames</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20730</th>\n",
       "      <td>Julianne Moore</td>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23919</th>\n",
       "      <td>Ali</td>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13077</th>\n",
       "      <td>Forest Whitaker</td>\n",
       "      <td>247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16800</th>\n",
       "      <td>Antonio Banderas</td>\n",
       "      <td>247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             primaryName  z_score\n",
       "4947        Nicolas Cage      252\n",
       "3620          Ray Liotta      250\n",
       "21009  Samuel L. Jackson      250\n",
       "21231     Robert De Niro      249\n",
       "7648        Bruce Willis      249\n",
       "8329         Ving Rhames      249\n",
       "20730     Julianne Moore      248\n",
       "23919                Ali      248\n",
       "13077    Forest Whitaker      247\n",
       "16800   Antonio Banderas      247"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print ('Top 10 most likely to be infected:')\n",
    "infected[['primaryName', 'z_score']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottom 10 least likely to be infected:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>primaryName</th>\n",
       "      <th>z_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15913</th>\n",
       "      <td>Ahmed Helmy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>Tatsuya Nakadai</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15301</th>\n",
       "      <td>Maaya Sakamoto</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7810</th>\n",
       "      <td>Masako Nozawa</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16498</th>\n",
       "      <td>Megumi Hayashibara</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14331</th>\n",
       "      <td>Metin Akpinar</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18645</th>\n",
       "      <td>Demet Akbag</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11686</th>\n",
       "      <td>Kamal Haasan</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7795</th>\n",
       "      <td>Mayumi Tanaka</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20302</th>\n",
       "      <td>Dhanush</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              primaryName  z_score\n",
       "15913         Ahmed Helmy        0\n",
       "208       Tatsuya Nakadai        0\n",
       "15301      Maaya Sakamoto        4\n",
       "7810        Masako Nozawa       26\n",
       "16498  Megumi Hayashibara       73\n",
       "14331       Metin Akpinar       93\n",
       "18645         Demet Akbag       93\n",
       "11686        Kamal Haasan      101\n",
       "7795        Mayumi Tanaka      105\n",
       "20302             Dhanush      117"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print ('Bottom 10 least likely to be infected:')\n",
    "infected[['primaryName', 'z_score']].tail(10).sort_values(by='z_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Z-score with other centrality measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I want to see how the z-score relates to other centrality measures and build a model to predict z-score.  First I begin by calculating some popular centrailty measures using NetworkX.\n",
    "\n",
    "I use the following centrality measures:\n",
    "    * Degree Centrality\n",
    "    * Closeness Centrality\n",
    "    * Betweeness Centrality\n",
    "    * PageRank\n",
    "\n",
    "After creating the measures, I add them to dataframe with .map()\n",
    "\n",
    "Note:  Betweenness Centrality often takes 15-20 minutes to run for graph based on the Top1000 dataframe.  I have included some code to save and retrieve the dictionaries that are created from the centrality measures in the Addendum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "degCent 0.0 seconds\n",
      "closeCent 2.56 minutes\n",
      "between 17.62 minutes\n",
      "p_rank 0.04 minutes\n"
     ]
    }
   ],
   "source": [
    "new_time = time.time()\n",
    "degCent = nx.degree_centrality(contagion_graph)\n",
    "print('degCent', round(time.time() - new_time,2), 'seconds')\n",
    "new_time = time.time()\n",
    "closeCent = nx.closeness_centrality(contagion_graph)\n",
    "print('closeCent', round((time.time() - new_time)/60,2), 'minutes')\n",
    "new_time = time.time()\n",
    "between = nx.betweenness_centrality(contagion_graph)\n",
    "print('between', round((time.time() - new_time)/60,2), 'minutes')\n",
    "new_time = time.time()\n",
    "p_rank = nx.pagerank(contagion_graph)\n",
    "print('p_rank',round(time.time() - new_time)2), 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Add centrality measures to infected df\n",
    "infected['degCent'] = infected['primaryName'].map(degCent)\n",
    "infected['closeCent'] = infected['primaryName'].map(closeCent)\n",
    "infected['between'] = infected['primaryName'].map(between)\n",
    "infected['p_rank'] = infected['primaryName'].map(p_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Analysis\n",
    "Let's see the correlation between Z-score and the centrality measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation betweeen Degree Centrality and z_score: 0.35\n",
      "Correlation betweeen Closeness Centrality and z_score: 0.96\n",
      "Correlation betweeen Betweenness Centrality and z_score: 0.32\n",
      "Correlation betweeen Page Rank and z_score: 0.94\n"
     ]
    }
   ],
   "source": [
    "print ('Correlation betweeen Degree Centrality and z_score:', round(infected['degCent'].corr(infected['z_score']),2))\n",
    "print ('Correlation betweeen Closeness Centrality and z_score:', round(infected['closeCent'].corr(infected['z_score']),2))\n",
    "print ('Correlation betweeen Betweenness Centrality and z_score:', round(infected['between'].corr(infected['z_score']),2))\n",
    "print ('Correlation betweeen Page Rank and z_score:', round(infected['degCent'].corr(infected['p_rank']),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like Closeness and Page Rank are pretty close to the Z-score.\n",
    "Now I'll see if I can predict it with a Gradient Boosting Regressor as well as a simple linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 for Gradient Boosted Regression: 0.9469\n"
     ]
    }
   ],
   "source": [
    "X = infected.drop(['isZombie','primaryName','z_score'], axis=1)\n",
    "y = infected['z_score']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "reg = GradientBoostingRegressor(random_state = 0).fit(X_train, y_train) \n",
    "y_pred = reg.predict(X_test)\n",
    "r2_GB = r2_score(y_test, y_pred)\n",
    "print(\"r2 for Gradient Boosted Regression: %.4f\" % r2_GB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 for Linear Regression: 0.9188\n"
     ]
    }
   ],
   "source": [
    "linreg = linear_model.LinearRegression()\n",
    "linreg.fit(X_train, y_train)\n",
    "y_pred2 = linreg.predict(X_test)\n",
    "r2_LR = r2_score(y_test, y_pred2)\n",
    "print(\"r2 for Linear Regression: %.4f\" % r2_LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the scores are fairly high, Centrality closeness has a .96 correlation.  Simply using it as a proxy would work better than the models!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addendum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A function to help evaluate how big your network will be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_eval(df):\n",
    "    start = time.time()\n",
    "    network = nx.from_pandas_dataframe(df, 'primaryTitle', 'primaryName')\n",
    "    net_time = time.time()\n",
    "    print ('network created: ', time.time() - net_time)\n",
    "    net_time = time.time()\n",
    "    print ('network is connected: ',nx.is_connected(network))\n",
    "    print ('edges: ', len(network.edges()))\n",
    "    print ('nodes: ', len(network.nodes()))\n",
    "    print ((time.time() - net_time), '\\n')\n",
    "\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "network created:  0.0\n",
      "network is connected:  False\n",
      "edges:  24513\n",
      "nodes:  13713\n",
      "0.031249523162841797 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<networkx.classes.graph.Graph at 0x1d6a9740320>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_eval(Top1000_actors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code to save and retrieve centrality measures\n",
    "[Hat tip to this Stack Overflow Article](https://stackoverflow.com/questions/18114628/pickling-multiple-dictionaries/18115159)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "MyDicts = [degCent, closeCent, between, p_rank]\n",
    "\n",
    "outputFile = open( \"myDicts.txt\", \"w\")\n",
    "outputFile.write(str(MyDicts))\n",
    "outputFile.flush()\n",
    "outputFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "inputFile = open( \"myDicts.txt\", \"r\")\n",
    "lines = inputFile.readlines()\n",
    "\n",
    "objects = []\n",
    "for line in lines:\n",
    "    objects.append( ast.literal_eval(line))\n",
    "\n",
    "degCent, closeCent, between,p_rank  = objects[0][0], objects[0][1], objects[0][2], objects[0][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMDbPY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMDB also has it's own Python library.  [Docs can be found here](https://imdbpy.readthedocs.io/en/latest/#). It even has a function to allow searches of titles by keyword.  I considered using it but after some data exploration, I decide against it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imdb import IMDb\n",
    "ia = IMDb()\n",
    "zombie_movies = ia.get_keyword('zombie')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all it only returns the top 50 per category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(zombie_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then there is this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wreck-It Ralph is a Zombie Movie!\n"
     ]
    }
   ],
   "source": [
    "for movie in zombie_movies:\n",
    "    if movie['title'] == 'Wreck-It Ralph':\n",
    "        print ('Wreck-It Ralph is a Zombie Movie!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't watch a lot of kids movies, but somehow I think that is not right.  Moral of the story, be sure to check any data before using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
